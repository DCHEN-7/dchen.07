<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic Page - Massively by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Projects</a>
					</header>
				<!-- Nav -->
				<nav id="nav">
					<ul class="links">
						<li class="active"><a href="index.html">KMeans Clustering</a></li>
						<li><a href="PCA.html">PCA</a></li>
						<li><a href="PBI_HR.html">POWER BI </a></li>
						<li><a href="linear_regression.html">Linear Regression</a></li>
						<li><a href="PBI_Project_MR.html">Excel</a></li>

				</nav>

				<!-- Main -->
					<div id="main">

						<!-- Featured Post -->
						<article class="post featured">
							<header class="major">
								<h2><a href="#"><u>E-Commerce Analysis</u></a></h2>
							</header>

							<div class = "box">
								<div class="box">
								<h4><u>Objective</u>: First, provide a comprehensive breakdown of the different customer groups within this E-Commerce company.
								Second, demonstrate how effective customer segmentation can be used provide valuable insight to product development teams and
							resource allocation decision-making.   </h4>
								</div>
								 <div class = "box">
									<p><b>Key Takeaways:</b></p>

									<p><u>Monetary's Extreme Outlier</u> <br />
										When building boxplots for the RFM metrics to identify outliers, we came across an extreme outlier for Monetary.
										This outlier here has a monetary score of 77183.6, or alternatively, possesses a Z-score of 65.5. Based on the staggering
										amount of standard deviation, it almost looks like a data entry error. However, given that the dataset has already gone
										through several cleaning workflows, its origins might not be so straightforward,
										and it is worth investigating how this data point came to be. That being said, for our model's sake, we have to remove it as 
										this point would easily cause our model to begin overfitting.  <br />
									
										<br /><img src="images/CS_monetarybox.png" height="275"> <br />
										<img src="images/CS_monoutlier1.png" height="175"> <br />
										<img src="images/CS_monooutlier2.png" height="175"> <br /> </p> 
										<br />

										<p><u>Optimal Number of Clusters</u> <br />
											Based on the elbow method WCSS plot, we identify the inflection point at k=4, and therefore, our optimal number of
											clusers is 4.  <br />

											<img src="images/CS_Elbow.png" height="375"> <br />


											<p><u>RFM Cluster Scores & Analysis</u> <br />
												After building our segmentation model, we calculate the average RFM scores for each cluster group.<br />
												<img src="images/CS_RFM_Dashboard.png" height="500"> <br />

												<h6>Note: On the plots the clusters are labelled 0,1,2,3 but we will be referring to them as 1,2,3,4.</h6>
	
												<br/> Kindly  remember that the recency metric is slightly inverted: <em>Recency</em> represents how <em>recently</em> they made their purchase by tracking the number of days
												<u>since their last purchase</u>. In other words, a high recency score means many days have passed since their last purchase.
												Similarly, a low recency score means they are recent customers.
												The others are straightforward metrics, Frequency means how 
													<em>frequently </em> they make purchases and Monetary means how <em>much</em> they're spending with their purchases. <br />

											<br /> <p style="color:green;">Cluster 1</p> <p>Ranks low in recency, relatively high in frequency, and moderate in monetary. This cluster likely represents
											the customers who are actively engaged with our products, but their monetary value suggests this group
											also tends to make value-concious spending decisions. </p>

											<br /> <p style="color:purple;">Cluster 2</p> <p>Ranks high in recency, low in frequency, and relatively low in monetary. 
												This cluster likely represents the customers who were unsatifsied with our product and are actively disinterested in our current 
											offerings and or promotional deals. </p>

											<br /> <p style="color:orange;">Cluster 3</p> <p>Ranks low in recency, extremely high in frequency, and low in monetary. 
												This cluster likely represents the customers who make purchases recently and regularly, but who strongly graviate towards
											lower spending choices. For exmaple, regularly shopping for lower-priced items while keeping a keen eye for discounts or clearance deals. </p>

											<br /> <p style="color:blue;">Cluster 4</p> <p>Ranks moderate in recency, low-moderate in frequency, and extremely high in monetary. 
												This cluster likely represents our high-value customers who show strong interest in our expensive premimum products and 
												are most willing to spend more money than any other customer group.   </p> <br />

												<p><u>Product Development Team Recommendations</u> <br />
											<p><em>1. Product Bundles</em> <br /> </p>

											<p>Targeting cluster 1, we could research into the top 3 most commonly purchased items within this group and then offer a 
												bundle purchase promotion where one item from the premier group is paired with a <em>slightly</em> less commonly bought items within this group. 
												The goal here is not trying to get this consumer group to purchase a new product, but rather incentivize them to
												purchase a product they typically would wait longer on. Additionally, based on the higher monetary score, we could experiment
												with item pricing combinations within this group to determine the optimal selling point.

												<p><em>2. Root Cause Analysis</em> <br /> </p>

												<p>Targeting cluster 2, we could designate a team to research each and every one of the purchase orders made by cluster 2
													and identify patterns and trends which correlate or perhaps even provide a causal explanation regarding why the customer
													was disinterested in returning for another purchase.

													<p><em>3. Engagement Products</em> <br /> </p>

													<p>Targeting cluster 3, we could design exclusive limited-time offer thank them for being a loyal customer, and then additionally
														provide discounts on typically higher-priced items they otherwise normally wouldn't consider due to the cost. The tricky
														part to this strategy, however, is that even with thorough research, it would be difficult to determine which products
														this consumer group has strayed away from due to complete disinterest versus which products have been shelved simply
														due to its price. If we had the right cookies enabled on our platform then it could be possible to identify items in which
														the user has placed into their cart, but not purchased as a guideline. 

														<p><em>4. VIP Programs</em> <br /> </p>

														<p>Targeting cluster 4, we could implement extra privileges to this consumer group which enhances their 
															customer experience and or provides a sense of exclusivity. For example, we could borrow from Artizia's
															"Clientele" program and slowly rollout the newest and best-selling products in waves, with this consumer group
															being first-in-line. Either way, some form of promotional offer which facilities a strong sense of pride
															within the customer.


											</p>
									</div>

									

					</div>

					<hr>
					<h4>Building the customer segmentation model in Python...</h4>
					<div class = "box">

						<p>Here is the inital CSV given:</p>
						<p><img src="images/CS_initalcsv.png" height="175"></p>
						<br />
						<p>The customer segmentation workflow we implmemented can essentially be summarized in the following 7 key steps (excluding sub-steps): <br />
							1. Transform the data as necessary (e.g. aggregate, new fields, etc.) in order to obtain the RFM scores. <br />
							2. Obtain the RFM scores and merge them to create one final RFM dataset  <br />
							3. Clean the RFM dataset, identifying and adressing duplicates, null values, outliers, etc. <br />
							4. Standarize the dataset (we'll use StandardScaler from SKLearn) <br />
							5. Determine the optimal number of clustering groups (we'll use Elbow Method) <br />
							6. Visualize the clusters in the manner most suitable for interpretation <br />
							7. Interpret and contexualize the resulting model in terms of business operation & strategy  

						</p>

						<p> Steps 1,4, and 5 are provided in detail below, with remaining steps posessessing less noteworthy code.</p>

						<p> 1. <br />
							
							The inital dataset was given in tabular form, meaning each row corresponding to a transaction. This tabular nature meant that for
							the recency metric, we were required to transform the dataset somehow such that each customerID only had 1 associated row. Furthermore,
							that transaction row had to be most recent transaction. 		

							<p><code>customers['rank'] = customers.sort_values(['CustomerID', 'Date']).groupby('CustomerID').cumcount() + 1 </code> <br />

								<br /> <img src="images/CS_RecencyCumCount.png" height="275"> <br />
							<br />This problem was solved by first sorting the dataframe by CustomerID and then by
							Date within each CustomerID. Afterwards, we created a calculated field called 'rank' through the .cumcount() function, which allowed us to track each
							transaction in sequence based on the sorted date. From here, it was just a matter of creating a new column 'recency' based on the number of elapsed time 
							between the earliest transactions (those with rank value of 1) and the most recent transaction  (those with the highest rank value).
							where 'rank' had a value of 1 (i.e. it was the first transaction). <br />

							<br /> The frequency and monetary metrics were much easier calculations to be had. <br />
							
							 <br />

							4 & 5. <br />

							Step 4 & 5 was suprisingly tricky as we know for the downstream cluster analysis, we want to perform the predictive machine learning algorithm <em>KMeans</em>
							on the standardized dataset. However, for business & strategy interpretations, we want the true values but with an added column representing the 
							algorithm's cluster assignment. <br /> 
							
							<br /> The following codes creates two RFM dataframes, one standardized and one not, and then begins a loop to create
							the WCSS scores for the elbow plot. Afterwards, we apply the <em>KMeans</em> algorithim to assign the cluster predictions and
							calculate the mean RFM values within each cluster. From there, we achieve our desired results of a customer segmentation model with their
							corresponding recency, frequency, and monetary scores.  <br />

							<p><code>RFM_set_new[columns] = scaler.fit_transform(RFM_set_new[columns]) </code> <br />
							<p><code>RFM_S = RFM_set_new.drop('CustomerID', axis=1)  </code> <br />
							<p><code>RFM_Pre_S = RFM_df </code> <br />

							<p><code>for k in range(1,10):<br />
								kmeans = KMeans(n_clusters=k) <br />
								kmeans.fit(RFM_S) <br />
								wcss_list.append(kmeans.inertia_)</code> <br />

								<p><code>kmeans = KMeans(n_clusters=4, random_state = 0) <br />
									kmeans.fit(RFM_S)</code> <br />

									<p><code>predictions = kmeans.predict(RFM_S) <br />
										df_rfm = pd.DataFrame(RFM_Pre_S) <br />
										df_rfm['cluster'] = predictions <br />
										avg_cluster_df = df_rfm.groupby(['cluster'], as_index=False).mean() </code> <br />

										<br /> <img src="images/CS_avgcluster_table.png" height="130"> <br />

										
						</p>
						</div>

						<div class = "box">
							This project was my first thorough attempt at applying a machine learning algorithim in a realistic business use case.
							 I learned a lot and hopefully it's clear in my work that this field is something I'm truly passionate about.
							<br /> Thank you for taking the time to take a look at my work!

						</div>
	
					

				

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Creative Commons</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>